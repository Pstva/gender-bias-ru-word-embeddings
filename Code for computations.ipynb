{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qAtc72q43zka"
   },
   "source": [
    "# Gender Bias in Word Embeddings for Russian Language\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OlU1_mIH05pY"
   },
   "outputs": [],
   "source": [
    "import gensim\n",
    "import scipy\n",
    "import statistics\n",
    "import numpy as np\n",
    "from numpy import mean\n",
    "import random\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sww2nezHFPi2"
   },
   "source": [
    "## Loading Word Embeddings\n",
    "\n",
    "from the site https://rusvectores.org/ru/models/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m8XPHQ8QL8JM"
   },
   "source": [
    "### Word embeddings used for the analysis:\n",
    "\n",
    "**Word2vec models with Universal dependecies tags**:\n",
    "\n",
    "\n",
    "1) ruscorpora_upos_cbow_300_20_2019 (http://vectors.nlpl.eu/repository/20/180.zip)\n",
    "\n",
    "2) ruwikiruscorpora_upos_skipgram_300_2_2019 (http://vectors.nlpl.eu/repository/20/182.zip)\n",
    "\n",
    "3) tayga_upos_skipgram_300_2_2019 (http://vectors.nlpl.eu/repository/20/185.zip)\n",
    "\n",
    "4) news_upos_skipgram_300_5_2019 (http://vectors.nlpl.eu/repository/20/184.zip)\n",
    "\n",
    "**Fasttext model without tags**\n",
    "\n",
    "1) geowac_lemmas_none_fasttextskipgram_300_5_2020 (http://vectors.nlpl.eu/repository/20/213.zip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3pTTcYiTL7W0"
   },
   "outputs": [],
   "source": [
    "we_models = {\"geowac_lemmas_none_fasttextskipgram_300_5_2020\": \"http://vectors.nlpl.eu/repository/20/213.zip\",\n",
    "             \"ruscorpora_upos_cbow_300_20_2019\" : \"http://vectors.nlpl.eu/repository/20/180.zip\",\n",
    "             \"ruwikiruscorpora_upos_skipgram_300_2_2019\": \"http://vectors.nlpl.eu/repository/20/182.zip\",\n",
    "             \"tayga_upos_skipgram_300_2_2019\":\"http://vectors.nlpl.eu/repository/20/185.zip\",\n",
    "             \"news_upos_skipgram_300_5_2019\":\"http://vectors.nlpl.eu/repository/20/184.zip\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5VZpbpcoCP3l"
   },
   "outputs": [],
   "source": [
    "#saving all the model in the folder \"we_models\"\n",
    "def get_models(model_url, model_name, path_to_save=\"/we_models/\"):\n",
    "    model_path = path_to_save + model_name + \".zip\"\n",
    "    urllib.request.urlretrieve(model_url, model_path)\n",
    "\n",
    "for model_name, model_url in we_models.items():\n",
    "    get_models(model_url, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ZztiG4NJQPt"
   },
   "outputs": [],
   "source": [
    "#we need to extract fasttext models from zip\n",
    "with zipfile.ZipFile(\"we_models/geowac_lemmas_none_fasttextskipgram_300_5_2020.zip\", 'r') as zip_ref: \n",
    "    zip_ref.extractall(\"we_models/geowac_lemmas_none_fasttextskipgram_300_5_2020\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5N0SYg2aL7aD"
   },
   "outputs": [],
   "source": [
    "#function for opening the we model from archieve (for word2vec models) or folder (for fasttext models)\n",
    "def open_model(model_name,model_path, is_fasttext = False):\n",
    "    if is_fasttext == False:\n",
    "        model_file = model_path + model_name + \".zip\"\n",
    "        with zipfile.ZipFile(model_file, 'r') as archive:\n",
    "            stream = archive.open('model.bin')\n",
    "            model = gensim.models.KeyedVectors.load_word2vec_format(stream, binary=True)\n",
    "    else:\n",
    "        model_file = model_path + model_name\n",
    "        model = gensim.models.KeyedVectors.load(model_file + \"/model.model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVRprHDr1JiH"
   },
   "source": [
    "## Word lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wX_74tZD05pe"
   },
   "outputs": [],
   "source": [
    "#attribute words\n",
    "male_terms = [\"мужчина_NOUN\", \"мужской_ADJ\", \"мальчик_NOUN\", \"брат_NOUN\", \"сын_NOUN\", \"отец_NOUN\", \"папа_NOUN\", \"дедушка_NOUN\", \"дядя_NOUN\"]\n",
    "female_terms = [\"женщина_NOUN\", \"женский_ADJ\", \"девочка_NOUN\", \"сестра_NOUN\", \"дочь_NOUN\", \"мать_NOUN\", \"мама_NOUN\", \"бабушка_NOUN\", \"тетя_NOUN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2FCqpYsn0CAj"
   },
   "outputs": [],
   "source": [
    "#target words\n",
    "#from the folder \"word_sets\"\n",
    "targ_weat_files = [\"career_family.txt\", \n",
    "             'math_arts.txt', \n",
    "             'science_arts.txt',\n",
    "             'intelligence_appearence.txt',\n",
    "             'strong_weak.txt',\n",
    "             'tech_human.txt',\n",
    "             'rational_emotional.txt']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xUZOVPg45tSe"
   },
   "source": [
    "### Getting the vectors for words from the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nlKzVJZn05pg"
   },
   "outputs": [],
   "source": [
    "#get the vector for a word from word embedding\n",
    "def get_vectors(model, list_of_words, pos_tag=True):\n",
    "    vectors = []\n",
    "    if pos_tag:\n",
    "        for w in list_of_words:\n",
    "            vectors.append(model[w.strip()])\n",
    "    else:\n",
    "        for w in list_of_words:\n",
    "            vectors.append(model[w[:w.find(\"_\")]])\n",
    "    return vectors\n",
    "\n",
    "#get all the vectors for a set of words\n",
    "def get_vectors_for_sets(model, sets, pos_tag=True):\n",
    "    set_vectors = []\n",
    "    for s in sets:\n",
    "        set_vectors.append(get_vectors(model, s, pos_tag))\n",
    "    return set_vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czuAfURf1V0v"
   },
   "source": [
    "## Functions for measuring bias with the Word Embedding Association Test (WEAT) method\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SJdcHz6y2hFM"
   },
   "source": [
    "### Calculating test statistic, effect size and p-value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WngMGdwS2YJr"
   },
   "outputs": [],
   "source": [
    "def cosine_vectors(v1, v2):\n",
    "    return np.dot(v1, v2)/norm(v1)/norm(v2)\n",
    "\n",
    "def similarity(w, A, B): #similarities between a word and two attribute sets\n",
    "    w_a_sim, w_b_sim = 0, 0\n",
    "    for i in range(len(A)):\n",
    "        w_a_sim += cosine_vectors(w, A[i])\n",
    "        w_b_sim += cosine_vectors(w, B[i])\n",
    "    return w_a_sim/len(A), w_b_sim/len(B)\n",
    "    \n",
    "def sets_difference(X, Y, A, B): #calculating test statistic\n",
    "    w_A_B_all= []\n",
    "    x_sim, y_sim = 0, 0\n",
    "    for i in range(len(X)):\n",
    "        x_a_sim, x_b_sim = similarity(X[i], A, B)\n",
    "        y_a_sim, y_b_sim = similarity(Y[i], A, B)\n",
    "        \n",
    "        x_sim += (x_a_sim - x_b_sim)\n",
    "        y_sim += (y_a_sim - y_b_sim)\n",
    "        \n",
    "        w_A_B_all.extend([x_a_sim, x_b_sim, y_a_sim, y_b_sim])\n",
    "    stdev_all_words = statistics.stdev(w_A_B_all) #for calculating effect size\n",
    "    return x_sim - y_sim, stdev_all_words\n",
    "\n",
    "def calc_p_value(X, Y, A, B,original_v): #randomization with 100000 iterations\n",
    "    test_statistics = []\n",
    "    len_X_Y = len(X) + len(Y)\n",
    "    indices_old = list(range(len_X_Y))\n",
    "    all_X_Y = X + Y\n",
    "    for i in range(100000):\n",
    "        X_ind = random.sample(indices_old, len_X_Y//2)\n",
    "        Y_ind = list(set(indices_old)-set(X_ind))\n",
    "        new_X = [all_X_Y[j] for j in X_ind]\n",
    "        new_Y = [all_X_Y[j] for j in Y_ind]\n",
    "        new_value, _ = sets_difference(new_X, new_Y, A, B)\n",
    "        test_statistics.append(new_value)\n",
    "    P_value = len([v for v in test_statistics if v >= original_v])/len(test_statistics)\n",
    "    return P_value\n",
    "\n",
    "def calc_bias(model, attr1, attr2, pos_tag=True):\n",
    "    X, Y, A, B = get_vectors_for_sets(model, [attr1, attr2, male_terms, female_terms],pos_tag)\n",
    "    original_v, stdev_all_words = sets_difference(X, Y, A, B)\n",
    "    effect_size = (original_v/len(X)) / stdev_all_words\n",
    "    p_value = calc_p_value(X, Y, A, B, original_v)\n",
    "    return effect_size, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tcyxwGPWMA3v"
   },
   "source": [
    "## Measuring gender bias with the WEAT method "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gdvgYCXdQveQ"
   },
   "outputs": [],
   "source": [
    "# file for results of calculations\n",
    "file_results = \"results.csv\"\n",
    "with open(file_results, \"w\") as f:\n",
    "    f.write(\"model,attr1,attr2,effect_size,p_value\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7yEl-mmP05pb"
   },
   "outputs": [],
   "source": [
    "we_models_names = [\"ruscorpora_upos_cbow_300_20_2019\",\"ruwikiruscorpora_upos_skipgram_300_2_2019\", \n",
    "                   \"tayga_upos_skipgram_300_2_2019\", \"news_upos_skipgram_300_5_2019\",\n",
    "                   \"geowac_lemmas_none_fasttextskipgram_300_5_2020\"]\n",
    "\n",
    "pos_tags = True #if the we model with POS-tags \n",
    "is_fastext = False #for fasttext models, zip should be unpacked, so another function for opening the model\n",
    "\n",
    "for we_num in range(len(we_models_names)):\n",
    "    we = we_models_names[we_num\n",
    "                         \n",
    "    if we.find(\"fasttext\") > 0:\n",
    "        is_fasttext = True\n",
    "    if we.find(\"upos\") != -1:\n",
    "        pos_tag = False\n",
    "                         \n",
    "    model = open_model(we, \"/we_models/\",\n",
    "                       is_fasttext = is_fasttext)\n",
    "    \n",
    "    for attr_weat_f in targ_weat_files:\n",
    "        file_path = \"/word_sets/{}\".format(attr_weat_f)\n",
    "        attr_weat = pd.read_csv(file_path)\n",
    "        attr1, attr2 = list(attr_weat.iloc[:,0]), list(attr_weat.iloc[:,1])\n",
    "        attr1_name, attr2_name = attr_weat.columns[0], attr_weat.columns[1]\n",
    "        effect_size, p_value = calc_bias(model, attr1, attr2,pos_tag=pos_tag)\n",
    "\n",
    "        with open(file_results, \"a\") as f:\n",
    "            f.write(we + \",\" + attr1_name + \",\" + attr2_name + \",\" + str(effect_size) + \",\" + str(p_value))\n",
    "            f.write(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Код для Диалога",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
